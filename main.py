import streamlit as st
import tempfile
import os
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from DB.insert import insert_data
from DB.connector import DBconnector

####################### ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” #######################

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "quiz_active" not in st.session_state:
    st.session_state.quiz_active = False
if "current_quiz" not in st.session_state:
    st.session_state.current_quiz = None
if "role_prompt" not in st.session_state:
    st.session_state.role_prompt = "This chatbot is designed to help slow learners who are vulnerable to various crimes. Please provide simple and short responses at a kindergarten level so that the user can easily understand. Also, communicate in a friendly and empathetic tone, like a close friend. Focus on crime prevention and provide helpful answers. All responses must be in Korean."

####################### ë©”ì¸ í™”ë©´ #######################

st.title("ë°”ë¼ë´‡ - ì¹œêµ¬ì²˜ëŸ¼ ë„ì™€ì£¼ëŠ” AI")

####################### ì‚¬ì´ë“œë°” #######################

st.sidebar.title("ì§ˆë¬¸ ì´ë ¥ :book:")
st.sidebar.write("---")

# DBì—ì„œ ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
def get_chat_history():
    try:
        with DBconnector() as sql:
            cursor = sql.conn.cursor(dictionary=True)
            cursor.execute("SELECT * FROM test ORDER BY id DESC LIMIT 10")
            chat_history = cursor.fetchall()
            return chat_history
    except Exception as e:
        print(f"Error fetching chat history: {e}")
        return []

# "ìƒˆë¡œìš´ ì§ˆë¬¸í•˜ê¸°" ë²„íŠ¼
if st.sidebar.button("ìƒˆë¡œìš´ ì§ˆë¬¸ í•˜ê¸°â•"):
    st.session_state.chat_history = []
    st.session_state.quiz_active = False
    st.session_state.current_quiz = None

# ì‚¬ì´ë“œë°”ì—ì„œ ì´ì „ ëŒ€í™” ì´ë ¥ ë²„íŠ¼ì„ í‘œì‹œ
chat_history = get_chat_history()
for idx, chat in enumerate(chat_history):
    if st.sidebar.button(f"{idx + 1}. {chat['question']}"):
        st.session_state.chat_history = [{"role": "user", "content": chat['question']}, {"role": "assistant", "content": chat['answer']}]

####################### íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ #######################

uploaded_file = st.file_uploader("ë²”ì£„ ì‚¬ë¡€ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.", type=['txt'])

def txt_to_document(uploaded_file):
    temp_dir = tempfile.TemporaryDirectory()
    temp_filepath = os.path.join(temp_dir.name, uploaded_file.name)
    with open(temp_filepath, "wb") as f:
        f.write(uploaded_file.getvalue())
    loader = TextLoader(temp_filepath)
    pages = loader.load_and_split()
    return pages

if uploaded_file:
    pages = txt_to_document(uploaded_file)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)
    texts = text_splitter.split_documents(pages)
    embeddings_model = OpenAIEmbeddings()
    text_vectors = [embeddings_model.embed_query(text.page_content) for text in texts]
    st.session_state.role_prompt = f"Please carefully assess whether the uploaded file's content resembles a crime-related situation. Provide simple and short responses at a kindergarten level so that the user can easily understand. Also, communicate in a friendly and empathetic tone, like a close friend. Focus on crime prevention and provide helpful answers. All responses must be in Korean."

####################### ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ #######################

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

if user_input:
    new_message = HumanMessage(content=user_input)
    st.session_state.chat_history.append(new_message)

    ####################### í€´ì¦ˆ ê¸°ëŠ¥ ì²˜ë¦¬ #######################

    if "í€´ì¦ˆ" in user_input and not st.session_state.quiz_active:
        def generate_quiz():
            quiz_prompt = """
            ì¹œêµ¬ì—ê²Œ ë„ì›€ì´ ë˜ëŠ” í€´ì¦ˆë¥¼ ë‚¼ê²Œ. ì§ˆë¬¸ì„ ë³´ê³  ì ì ˆí•œ ì„ íƒì„ í•´ì¤˜.
            ìƒí™©: "ê¸¸ì„ ê±·ë‹¤ê°€ ëˆ„êµ°ê°€ê°€ ë‹¤ê°€ì™€ ë¬´ì–¸ê°€ë¥¼ ì‚¬ë‹¬ë¼ê³  ìš”ì²­í–ˆì–´ìš”. ì–´ë–»ê²Œ í• ê¹Œìš”?"
            1. ë°”ë¡œ ì‚¬ì¤€ë‹¤.
            2. ì´ìœ ë¥¼ ë¬»ê³  ë„ì™€ì¤„ ë°©ë²•ì„ ìƒê°í•œë‹¤.
            3. ê·¸ëƒ¥ ë¬´ì‹œí•˜ê³  ì§€ë‚˜ê°„ë‹¤.
            """
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            result = llm.invoke([SystemMessage(content=quiz_prompt)])
            return result.content
        
        quiz = generate_quiz()
        st.session_state.quiz_active = True
        st.session_state.current_quiz = quiz
        st.chat_message("assistant", avatar="ğŸ¤–").write(quiz)

    ####################### í€´ì¦ˆ ì‘ë‹µ ì²˜ë¦¬ #######################

    elif st.session_state.quiz_active:
        def evaluate_answer(user_answer, quiz_question):
            prompt = f"""
            ì‚¬ìš©ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³ , ì •ë‹µê³¼ ì„¤ëª…ì„ ì œê³µí•´ì¤˜. 
            í€´ì¦ˆ: {quiz_question} 
            ì‚¬ìš©ìì˜ ë‹µë³€: {user_answer}
            """
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            result = llm.invoke([SystemMessage(content=prompt)])
            return result.content
        
        evaluation = evaluate_answer(user_input, st.session_state.current_quiz)
        st.session_state.quiz_active = False
        st.chat_message("assistant", avatar="ğŸ¤–").write(evaluation)

    ####################### ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ #######################

    else:
        messages = [SystemMessage(content=st.session_state.role_prompt)] + st.session_state.chat_history
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        result = llm.invoke(messages)
        new_response = AIMessage(content=result.content)
        st.session_state.chat_history.append(new_response)
        st.chat_message("assistant", avatar="ğŸ¤–").write(new_response.content)
        insert_data(user_input, new_response.content)

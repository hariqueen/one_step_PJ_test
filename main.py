__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
import tempfile
import os
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from DB.insert import insert_data  # MySQLì— ì €ì¥í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
from DB.connector import DBconnector  # MySQL DB ì—°ê²°
import openai

####################### ë©”ì¸ í™”ë©´ ì„¸íŒ… #######################

st.set_page_config(page_title="í•œê±¸ìŒAI í”„ë¡œí† íƒ€ì…")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "sidebar_history" not in st.session_state:
    st.session_state.sidebar_history = []
if "full_history" not in st.session_state:
    st.session_state.full_history = []
if "session_active" not in st.session_state:
    st.session_state.session_active = False

st.title("ë°”ë¼ë´‡")
st.title('ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?')

####################### ì‚¬ì´ë“œë°” #######################

st.sidebar.title("ì§ˆë¬¸ ì´ë ¥ :book:")
st.sidebar.write("---")

# MySQLì—ì„œ ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
def get_chat_history():
    try:
        with DBconnector() as sql:
            cursor = sql.conn.cursor(dictionary=True)
            cursor.execute("SELECT * FROM test ORDER BY id DESC LIMIT 10")  # ìµœê·¼ 10ê°œì˜ ëŒ€í™” ì´ë ¥ì„ ê°€ì ¸ì˜´
            chat_history = cursor.fetchall()
            return chat_history
    except mysql.connector.Error as e:
        print(f"Error fetching chat history: {e}")
        return []

# "ìƒˆë¡œìš´ ì§ˆë¬¸í•˜ê¸°" ë²„íŠ¼
if st.sidebar.button("ìƒˆë¡œìš´ ì§ˆë¬¸ í•˜ê¸°â•"):
    st.session_state.chat_history = []
    st.session_state.restored_session = False

# ì‚¬ì´ë“œë°”ì—ì„œ ì´ì „ ëŒ€í™” ì´ë ¥ ë²„íŠ¼ì„ í‘œì‹œ
chat_history = get_chat_history()
for idx, chat in enumerate(chat_history):
    if st.sidebar.button(f"{idx + 1}. {chat['question']}"):
        st.session_state.chat_history = [{"role": "user", "content": chat['question']}, {"role": "assistant", "content": chat['answer']}]
        st.session_state.restored_session = True

####################### íŒŒì¼ ì—…ë¡œë“œ ë° GPT ì„¤ì • #######################

uploaded_file = st.file_uploader("í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”!", type=['txt'])

def txt_to_document(uploaded_file):
    temp_dir = tempfile.TemporaryDirectory()
    temp_filepath = os.path.join(temp_dir.name, uploaded_file.name)
    with open(temp_filepath, "wb") as f:
        f.write(uploaded_file.getvalue())
    loader = TextLoader(temp_filepath)
    pages = loader.load_and_split()
    return pages

if uploaded_file is not None:
    pages = txt_to_document(uploaded_file)

    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)
    texts = text_splitter.split_documents(pages)

    embeddings_model = OpenAIEmbeddings()

    # í…ìŠ¤íŠ¸ ë²¡í„°í™”
    text_vectors = [embeddings_model.embed_query(text.page_content) for text in texts]

    # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì²˜ìŒ 1000ê¸€ìê¹Œì§€ë§Œ ì‚¬ìš©
    document_summary = " ".join([text.page_content for text in texts])[:1000]
    role_prompt = f"ê²½ê³„ì„± ì§€ëŠ¥ ì¥ì• ê°€ ìˆëŠ” ì‚¬ëŒì„ ìœ„í•´ ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¹œêµ¬ì²˜ëŸ¼ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”."

    st.header("ì–´ë–¤ ì§ˆë¬¸ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")

    # ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥
    question = st.text_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”', value='')

    if "í€´ì¦ˆ" in question:
        # í€´ì¦ˆ ìƒì„± ë¡œì§
        def generate_quiz():
            prompt = f"""
            {role_prompt}
            ë‹¹ì‹ ì€ ê²½ê³„ì„± ì§€ëŠ¥ ì¥ì• ê°€ ìˆëŠ” ì‚¬ëŒë“¤ì„ ìœ„í•œ í€´ì¦ˆë¥¼ ì¶œì œí•˜ëŠ” AIì…ë‹ˆë‹¤. ì´ í€´ì¦ˆëŠ” ìœ„í—˜í•œ ìƒí™©ì—ì„œ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ë¬»ëŠ” í€´ì¦ˆì…ë‹ˆë‹¤. ìƒí™©ì„ ì£¼ê³ , 3ê°œì˜ ì„ íƒì§€ë¥¼ ì œê³µí•˜ê³ , ì •ë‹µê³¼ í•´ì„¤ë„ ì œê³µí•©ë‹ˆë‹¤.
            """
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            result = llm({"messages": [{"role": "system", "content": prompt}]})
            return result["choices"][0]["message"]["content"]

        quiz = generate_quiz()
        st.write(quiz)

        # ì‚¬ìš©ìì˜ í€´ì¦ˆ ë‹µë³€ì„ ë°›ìŒ
        user_answer = st.text_input('ë‹¹ì‹ ì˜ ë‹µì€ ë¬´ì—‡ì¸ê°€ìš”?')

        # GPTì—ê²Œ ì •ë‹µì„ í‰ê°€í•˜ë„ë¡ ìš”ì²­
        def evaluate_answer(user_answer, quiz_question):
            prompt = f"""
            {role_prompt}
            ë‹¤ìŒ í€´ì¦ˆì— ëŒ€í•œ ì‚¬ìš©ìì˜ ë‹µë³€ì„ í‰ê°€í•´ ì£¼ì„¸ìš”.
            í€´ì¦ˆ:
            {quiz_question}
            ì‚¬ìš©ìì˜ ë‹µë³€: {user_answer}
            """
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            result = llm({"messages": [{"role": "system", "content": prompt}]})
            return result["choices"][0]["message"]["content"]

        if st.button('ì •ë‹µ í™•ì¸'):
            evaluation = evaluate_answer(user_answer, quiz)
            st.write(evaluation)

    elif question:
        # ì§ˆë¬¸ì„ ì„¸ì…˜ì— ì €ì¥
        new_message = {"role": "user", "content": question}
        st.session_state.chat_history.append(new_message)

        # GPT ëª¨ë¸ì„ í†µí•´ ë‹µë³€ ìƒì„±
        messages = [{"role": "system", "content": role_prompt}] + st.session_state.chat_history
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        result = llm({"messages": messages})

        # ì±—ë´‡ ë‹µë³€ ì €ì¥
        new_response = {"role": "assistant", "content": result["choices"][0]["message"]["content"]}
        st.session_state.chat_history.append(new_response)

        # ì±—ë´‡ ë‹µë³€ ì¶œë ¥
        st.write(new_response["content"])

        # MySQLì— ì§ˆë¬¸ê³¼ ì‘ë‹µì„ ì €ì¥
        insert_data(question, new_response["content"])

# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.chat_history:
    role = "ğŸ»" if message["role"] == "assistant" else "ğŸ˜ƒ"
    st.write(f"{role}: {message['content']}")

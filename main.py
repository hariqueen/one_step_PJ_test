import streamlit as st
import tempfile
import os
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from DB.insert import insert_data
from DB.connector import DBconnector

####################### ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” #######################

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "quiz_active" not in st.session_state:
    st.session_state.quiz_active = False
if "current_quiz" not in st.session_state:
    st.session_state.current_quiz = None
if "role_prompt" not in st.session_state:
    st.session_state.role_prompt = """
    ì´ ì±—ë´‡ì€ ê°ì¢… ë²”ì£„ì— ë…¸ì¶œë˜ê¸° ì‰¬ìš´ ëŠë¦°í•™ìŠµìë¥¼ ë•ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ, ìœ ì¹˜ì› ìˆ˜ì¤€ì˜ ê°„ë‹¨í•˜ê³  ì§§ì€ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
    ë˜í•œ ì¹œê·¼í•œ ì¹œêµ¬ì²˜ëŸ¼ ìƒëƒ¥í•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.
    ë²”ì£„ ì˜ˆë°©ì— ì´ˆì ì„ ë§ì¶”ì–´ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ë§ë¡œí•˜ì„¸ìš”.
    """

if "sidebar_history" not in st.session_state:
    st.session_state.sidebar_history = []
if "full_history" not in st.session_state:
    st.session_state.full_history = []
if "restored_session" not in st.session_state:
    st.session_state.restored_session = False

####################### ë©”ì¸ í™”ë©´ #######################

st.title("ë°”ë¼ë´‡ - ì¹œêµ¬ì²˜ëŸ¼ ë„ì™€ì£¼ëŠ” AI")

####################### ì‚¬ì´ë“œë°” #######################

st.sidebar.title("ì§ˆë¬¸ ì´ë ¥ :book:")
st.sidebar.write("---")

# DBì—ì„œ ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
def get_chat_history():
    try:
        with DBconnector() as sql:
            cursor = sql.conn.cursor(dictionary=True)
            cursor.execute("SELECT * FROM test ORDER BY id DESC LIMIT 10")
            chat_history = cursor.fetchall()
            return chat_history
    except Exception as e:
        print(f"Error fetching chat history: {e}")
        return []

# "ìƒˆë¡œìš´ ì§ˆë¬¸í•˜ê¸°" ë²„íŠ¼
if st.sidebar.button("ìƒˆë¡œìš´ ì§ˆë¬¸ í•˜ê¸°â•"):
    # í˜„ì¬ ëŒ€í™” ì´ë ¥ì´ ì¡´ì¬í•˜ê³ , ì„¸ì…˜ì´ ë³µì›ëœ ìƒíƒœê°€ ì•„ë‹Œ ê²½ìš°
    if st.session_state.chat_history and not st.session_state.get('restored_session', False):
        # ì‚¬ì´ë“œë°” ì´ë ¥ì— ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ ì¶”ê°€
        first_user_question = next((msg for msg in st.session_state.chat_history if msg["role"] == "user"), None)

        if first_user_question:
            st.session_state.sidebar_history.append(first_user_question)

        # í˜„ì¬ ëŒ€í™” ì´ë ¥ì„ full_historyì— ì €ì¥
        st.session_state.full_history.append(st.session_state.chat_history.copy())

    # ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
    st.session_state.chat_history = []

    # ì„¸ì…˜ì´ ë³µì›ëœ ìƒíƒœë¥¼ Falseë¡œ ì„¤ì •
    st.session_state.restored_session = False

# ì‚¬ì´ë“œë°”ì—ì„œ ì´ì „ ëŒ€í™” ì´ë ¥ ë²„íŠ¼ì„ í‘œì‹œ
for idx, question in enumerate(st.session_state.sidebar_history):
    if st.sidebar.button(f"{idx + 1}. {question['content']}"):
        # ì„ íƒëœ ì„¸ì…˜ì˜ ëŒ€í™” ì´ë ¥ ë¡œë“œ
        st.session_state.chat_history = st.session_state.full_history[idx]

        # ì„¸ì…˜ì´ ë³µì›ëœ ìƒíƒœë¥¼ Trueë¡œ ì„¤ì •
        st.session_state.restored_session = True

####################### íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ #######################

uploaded_file = st.file_uploader("ë²”ì£„ ì‚¬ë¡€ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.", type=['txt'])

def txt_to_document(uploaded_file):
    temp_dir = tempfile.TemporaryDirectory()
    temp_filepath = os.path.join(temp_dir.name, uploaded_file.name)
    with open(temp_filepath, "wb") as f:
        f.write(uploaded_file.getvalue())
    loader = TextLoader(temp_filepath)
    pages = loader.load_and_split()
    return pages

if uploaded_file:
    pages = txt_to_document(uploaded_file)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)
    texts = text_splitter.split_documents(pages)
    embeddings_model = OpenAIEmbeddings()
    text_vectors = [embeddings_model.embed_query(text.page_content) for text in texts]
    st.session_state.role_prompt = f"""
    ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë‚´ìš©ì´ ë²”ì£„ì™€ ê´€ë ¨ëœ ìƒí™©ê³¼ ë¹„ìŠ·í•œì§€ ì‹ ì¤‘í•˜ê²Œ í™•ì¸í•´ ì£¼ì„¸ìš”.
    ì‚¬ìš©ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìœ ì¹˜ì› ìˆ˜ì¤€ì˜ ê°„ë‹¨í•˜ê³  ì§§ì€ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    ë˜í•œ ì¹œí•œ ì¹œêµ¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬ë¡œ ì†Œí†µí•˜ì„¸ìš”. ë²”ì£„ ì˜ˆë°©ì— ì´ˆì ì„ ë§ì¶”ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    """

####################### ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ #######################

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

if user_input:
    new_message = {"role": "user", "content": user_input}
    st.session_state.chat_history.append(new_message)

    # ëŒ€í™” ì´ë ¥ í‘œì‹œ (ì‚¬ìš©ì ì§ˆë¬¸ í¬í•¨)
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"], avatar="ğŸ»" if message["role"] == "assistant" else None):
            st.write(message["content"])

    ####################### í€´ì¦ˆ ë° ë‹µë³€ í‰ê°€ í†µí•© ì²˜ë¦¬ #######################

    if "í€´ì¦ˆ" in user_input:
        # GPTì—ê²Œ í€´ì¦ˆì™€ í•´ì„¤ì„ ëª¨ë‘ ìš”ì²­í•˜ëŠ” ë‹¨ì¼ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë„ˆëŠ” ë²”ì£„ ì˜ˆë°©ì„ ìœ„í•œ ë„ì›€ì„ ì œê³µí•˜ëŠ” AIì•¼. ì‚¬ìš©ìì—ê²Œ ë²”ì£„ ì˜ˆë°©ê³¼ ê´€ë ¨ëœ í€´ì¦ˆë¥¼ ì¶œì œí•˜ê³ ,
        ì‚¬ìš©ìê°€ ë‹µì„ ë§í•˜ë©´ ê·¸ ë‹µì´ ë§ì•˜ëŠ”ì§€ í‹€ë ¸ëŠ”ì§€ í‰ê°€í•˜ê³  í•´ì„¤ì„ ì œê³µí•´ì¤˜.
        
        ì˜ˆì‹œ:
        ìƒí™©: "ê¸¸ì„ ê±·ë‹¤ê°€ ëˆ„êµ°ê°€ê°€ ë‹¤ê°€ì™€ ë¬´ì–¸ê°€ë¥¼ ì‚¬ë‹¬ë¼ê³  ìš”ì²­í–ˆì–´ìš”. ì–´ë–»ê²Œ í• ê¹Œìš”?"
        1. ë°”ë¡œ ì‚¬ì¤€ë‹¤.
        2. ì´ìœ ë¥¼ ë¬»ê³  ë„ì™€ì¤„ ë°©ë²•ì„ ìƒê°í•œë‹¤.
        3. ê·¸ëƒ¥ ë¬´ì‹œí•˜ê³  ì§€ë‚˜ê°„ë‹¤.

        ì´ì œ ìƒˆë¡œìš´ ìƒí™©ê³¼ 3ê°œì˜ ì„ íƒì§€ë¥¼ ì œì‹œí•´ì¤˜. ê·¸ë¦¬ê³  ì‚¬ìš©ìê°€ ë‹µë³€ì„ ì œì¶œí•˜ë©´ ì •ë‹µì„ ì•Œë ¤ì£¼ê³  í•´ì„¤ì„ ì œê³µí•´ì¤˜.
        """
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        result = llm.invoke([SystemMessage(content=prompt)])

        # í€´ì¦ˆì™€ ê²°ê³¼ë¥¼ ì²˜ë¦¬
        new_response = {"role": "assistant", "content": result.content}
        st.session_state.chat_history.append(new_response)
        st.chat_message("assistant", avatar="ğŸ¤–").write(new_response["content"])

    else:
        # ì¼ë°˜ì ì¸ ì§ˆë¬¸ ì²˜ë¦¬
        messages = [SystemMessage(content=st.session_state.role_prompt)] + st.session_state.chat_history
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        result = llm.invoke(messages)
        new_response = {"role": "assistant", "content": result.content}
        st.session_state.chat_history.append(new_response)
        st.chat_message("assistant", avatar="ğŸ¤–").write(new_response["content"])

    # DBì— ë°ì´í„° ì¶”ê°€
    insert_data(user_input, new_response["content"])

####################### ì´ì „ ëŒ€í™” ë‚´ì—­ í‘œì‹œ #######################

if not user_input:
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"], avatar="ğŸ»" if message["role"] == "assistant" else None):
            st.write(message["content"])
